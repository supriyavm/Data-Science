{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "import csv\n",
    "import cv2\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "import keras\n",
    "import keras.backend as k\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "os.listdir()\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "\n",
    "PATH=\"MURA-v1.1/\"\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "\n",
    "os.listdir(PATH)\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "train_imgs_path=pd.read_csv(PATH+'train_image_paths.csv')\n",
    "train_labels=pd.read_csv(PATH+'train_labeled_studies.csv')\n",
    "test_imgs_path=pd.read_csv(PATH+'valid_image_paths.csv')\n",
    "test_labels=pd.read_csv(PATH+'valid_labeled_studies.csv')\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "\n",
    "train_imgs_path.head()\n",
    "\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "\n",
    "train_imgs_path.shape\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "\n",
    "train_labels.head(20)\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "\n",
    "train_labels['1'].value_counts()\n",
    "\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "\n",
    "test_imgs_path.head(30)\n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "\n",
    "test_imgs_path.shape\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "for path in train_imgs_path.values[:10]:\n",
    "    img=cv2.imread(path[:10])\n",
    "    plt.imshow(plt.imread(path[:10]))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print (img.shape)\n",
    "\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "\n",
    "train_labels['Body_Part']=train_labels['MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/'].apply(lambda x: str(x.split('/')[2])[3:])\n",
    "train_labels['Study_Type']=train_labels['MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/'].apply(lambda x: str(x.split('/')[4])[:6])\n",
    "test_labels['Body_Part']=test_labels['MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/'].apply(lambda x: str(x.split('/')[2])[3:])\n",
    "test_labels['Study_Type']=test_labels['MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/'].apply(lambda x: str(x.split('/')[4])[:6])\n",
    "\n",
    "\n",
    "# In[58]:\n",
    "\n",
    "\n",
    "\n",
    "train_labels.head()\n",
    "\n",
    "\n",
    "# In[59]:\n",
    "\n",
    "\n",
    "\n",
    "test_labels.head()\n",
    "\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "\n",
    "\n",
    "sns.countplot(train_labels['1'])\n",
    "\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.countplot(data=train_labels,x='Body_Part',hue='1')\n",
    "\n",
    "\n",
    "# In[280]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.countplot(data=test_labels,x='Body_Part',hue='1')\n",
    "\n",
    "\n",
    "# In[64]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.countplot(data=train_labels,x='Study_Type',hue='1')\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "\n",
    "sns.countplot(test_labels['1'])\n",
    "\n",
    "\n",
    "# In[67]:\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.countplot(data=test_labels,x='Study_Type',hue='1')\n",
    "\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# In[78]:\n",
    "\n",
    "\n",
    "def read_image(Path):\n",
    "    img=cv2.imread(Path)\n",
    "    #img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    #print (img.shape)\n",
    "    img=np.array(img)\n",
    "    #img=np.resize(img,(224,224))\n",
    "    #print (img.shape)\n",
    "    img=img/255.\n",
    "    return img\n",
    "\n",
    "\n",
    "# In[79]:\n",
    "\n",
    "\n",
    "X_train=[]\n",
    "X_val=[]\n",
    "\n",
    "\n",
    "# In[82]:\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "# In[83]:\n",
    "\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "\n",
    "# In[88]:\n",
    "\n",
    "\n",
    "train_labels['MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/']=train_imgs_path['MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png']\n",
    "test_labels['MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/']=test_imgs_path['MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/image1.png']\n",
    "\n",
    "\n",
    "# In[89]:\n",
    "\n",
    "\n",
    "train_df=train_labels.groupby(['1']).apply(lambda x: x.sample(5000,replace=True))\n",
    "\n",
    "\n",
    "# In[90]:\n",
    "\n",
    "\n",
    "\n",
    "train_df.shape\n",
    "\n",
    "\n",
    "# In[91]:\n",
    "\n",
    "\n",
    "\n",
    "train_labels.shape\n",
    "\n",
    "\n",
    "# In[92]:\n",
    "\n",
    "\n",
    "\n",
    "sns.countplot(data=train_df,x='Body_Part',hue='1')\n",
    "\n",
    "\n",
    "# In[109]:\n",
    "\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16,preprocess_input,decode_predictions\n",
    "\n",
    "\n",
    "# In[117]:\n",
    "\n",
    "\n",
    "\n",
    "IMG_SIZE=(224,224)\n",
    "def __init__(contrast_stretching=False,#####\n",
    "histogram_equalization=False,#####\n",
    "adaptive_equalization=False,#####\n",
    " data_format=None):\n",
    " if data_format is None:\n",
    "\n",
    "   data_format = K.image_data_format()\n",
    "\n",
    "   self.counter = 0\n",
    "\n",
    "   self.contrast_stretching = contrast_stretching #####\n",
    "\n",
    "   self.adaptive_equalization = adaptive_equalization #####\n",
    "\n",
    "   self.histogram_equalization = histogram_equalization #####\n",
    "\n",
    "\n",
    "# In[273]:\n",
    "\n",
    "\n",
    "datagen=ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=30,\n",
    "    shear_range=0.4,\n",
    "    zoom_range=0.4,\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "\n",
    "# In[249]:\n",
    "\n",
    "\n",
    "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n",
    "    base_dir = os.path.dirname(in_df[path_col].values[0])\n",
    "    print('## Ignore next message from keras, values are replaced anyways')\n",
    "    df_gen = img_data_gen.flow_from_directory(base_dir, \n",
    "                                     class_mode = 'sparse',\n",
    "                                    **dflow_args)\n",
    "    df_gen.filenames = in_df[path_col].values\n",
    "    df_gen.classes = np.stack(in_df[y_col].values)\n",
    "    df_gen.samples = in_df.shape[0]\n",
    "    df_gen.n = in_df.shape[0]\n",
    "    df_gen._set_index_array()\n",
    "    df_gen.directory = '' # since we have the full path\n",
    "    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n",
    "    return df_gen\n",
    "\n",
    "\n",
    "# In[250]:\n",
    "\n",
    "\n",
    "train_gen = flow_from_dataframe(datagen, train_df, \n",
    "                             path_col = 'MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/',\n",
    "                            y_col = '1', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = 64)\n",
    "\n",
    "\n",
    "# In[251]:\n",
    "\n",
    "\n",
    "\n",
    "valid_gen = flow_from_dataframe(datagen, test_labels, \n",
    "                             path_col = 'MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/',\n",
    "                            y_col = '1', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = 64)\n",
    "\n",
    "\n",
    "# In[252]:\n",
    "\n",
    "\n",
    "\n",
    "test_X, test_Y = next(flow_from_dataframe(datagen, \n",
    "                               test_labels, \n",
    "                             path_col = 'MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/',\n",
    "                            y_col = '1', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = 64)) # one big batch\n",
    "# used a fixed dataset for final evaluation\n",
    "final_test_X, final_test_Y = next(flow_from_dataframe(datagen, \n",
    "                            test_labels, \n",
    "                            path_col = 'MURA-v1.1/valid/XR_WRIST/patient11185/study1_positive/',\n",
    "                            y_col = '1',\n",
    "                            target_size = IMG_SIZE,\n",
    "                            color_mode = 'rgb',\n",
    "                            batch_size = 64)) # one big batch\n",
    "\n",
    "\n",
    "# In[253]:\n",
    "\n",
    "\n",
    "\n",
    "t_x,t_y=next(train_gen)\n",
    "\n",
    "\n",
    "# In[254]:\n",
    "\n",
    "\n",
    "fig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = -127, vmax = 127)\n",
    "    c_ax.set_title('%s' % ('Pos' if c_y>0.5 else 'Neg'))\n",
    "    c_ax.axis('off')\n",
    "\n",
    "\n",
    "# In[255]:\n",
    "\n",
    "\n",
    "from keras.layers import  Convolution2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "from keras.models import  Sequential\n",
    "\n",
    "\n",
    "# In[279]:\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3,3), activation='relu', padding='same',input_shape = t_x.shape[1:]))\n",
    "#if you resize the image above, change the input shape\n",
    "model.add(Convolution2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(64, (3,3), activation='relu', padding='same'))\n",
    "model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(128, (3,3), activation='relu', padding='same'))\n",
    "model.add(Convolution2D(128, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# In[259]:\n",
    "\n",
    "\n",
    "base_model=VGG16(input_shape=t_x.shape[1:],include_top=False,weights='imagenet')\n",
    "base_model.trainable=False\n",
    "\n",
    "\n",
    "# In[260]:\n",
    "\n",
    "\n",
    "\n",
    "base_model.summary()\n",
    "\n",
    "\n",
    "# In[261]:\n",
    "\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "\n",
    "\n",
    "# In[262]:\n",
    "\n",
    "\n",
    "pt_features = Input(base_model.get_output_shape_at(0)[1:], name = 'feature_input')\n",
    "pt_depth = base_model.get_output_shape_at(0)[-1]\n",
    "\n",
    "\n",
    "# In[263]:\n",
    "\n",
    "\n",
    "pt_features\n",
    "\n",
    "\n",
    "# In[264]:\n",
    "\n",
    "\n",
    "\n",
    "pt_depth\n",
    "\n",
    "\n",
    "# In[275]:\n",
    "\n",
    "\n",
    "bn_features = BatchNormalization()(pt_features)\n",
    "# here we do an attention mechanism to turn pixels in the GAP on an off\n",
    "attn_layer = Conv2D(128, kernel_size = (1,1), padding = 'same', activation = 'relu')(bn_features)\n",
    "attn_layer = Conv2D(32, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
    "attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
    "attn_layer = AvgPool2D((2,2), strides = (1,1), padding = 'same')(attn_layer) # smooth results\n",
    "attn_layer = Conv2D(1, \n",
    "                    kernel_size = (1,1), \n",
    "                    padding = 'valid', \n",
    "                    activation = 'sigmoid')(attn_layer)\n",
    "# fan it out to all of the channels\n",
    "up_c2_w = np.ones((1, 1, 1, pt_depth))\n",
    "up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', \n",
    "               activation = 'linear', use_bias = False, weights = [up_c2_w])\n",
    "up_c2.trainable = False\n",
    "attn_layer = up_c2(attn_layer)\n",
    "\n",
    "mask_features = multiply([attn_layer, bn_features])\n",
    "gap_features = GlobalAveragePooling2D()(mask_features)\n",
    "gap_mask = GlobalAveragePooling2D()(attn_layer)\n",
    "# to account for missing values from the attention model\n",
    "gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n",
    "gap_dr = Dropout(0.5)(gap)\n",
    "dr_steps = Dropout(0.5)(Dense(128, activation = 'elu')(gap_dr))\n",
    "out_layer = Dense(1, activation = 'sigmoid')(dr_steps)\n",
    "\n",
    "attn_model = Model(inputs = [pt_features], outputs = [out_layer], name = 'attention_model')\n",
    "\n",
    "attn_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n",
    "                           metrics = ['binary_accuracy'])\n",
    "\n",
    "attn_model.summary()\n",
    "\n",
    "\n",
    "# In[277]:\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.best.hdf5\".format('cardio_attn')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', min_delta=0.0001, cooldown=5, min_lr=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=10) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]\n",
    "\n",
    "\n",
    "# In[278]:\n",
    "\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.util.Sequence import Sequence\n",
    "\n",
    "\n",
    "# In[268]:\n",
    "\n",
    "\n",
    "model = Sequential(name = 'combined_model')\n",
    "model.add(base_model)\n",
    "model.add(attn_model)\n",
    "model.compile(optimizer = Adam(lr = 1e-3), loss = 'binary_crossentropy',\n",
    "                           metrics = ['binary_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# In[272]:\n",
    "\n",
    "\n",
    "train_gen.batch_size = 64\n",
    "model.fit_generator(train_gen, \n",
    "                      validation_data = (test_X, test_Y), \n",
    "                    steps_per_epoch=100,\n",
    "                      epochs = 3, \n",
    "                      callbacks = callbacks_list,\n",
    "                      workers = 3)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
